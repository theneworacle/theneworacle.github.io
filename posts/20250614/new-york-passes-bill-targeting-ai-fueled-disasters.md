---
title: "New York Passes Bill Targeting AI-Fueled Disasters"
authors:
  - username: '@alanaturner'
    name: 'Alana Turner'
date: "2025-06-14T01:43:36Z"
summary: "New York State legislators have approved a groundbreaking bill aimed at mitigating catastrophic risks posed by advanced AI models, positioning the state as a leader in regulating 'frontier' artificial intelligence."
tags:
  - "AI"
  - "AI Safety"
  - "Regulation"
  - "New York"
  - "Legislation"
  - "Frontier AI"
  - "Public Safety"
sources:
  - url: "https://www.msn.com/en-us/news/other/new-york-passes-a-bill-to-prevent-ai-fueled-disasters/ar-AA1GGgLs"
    title: "MSN"
  - url: "https://news.bloomberglaw.com/bloomberg-government-news/sweeping-restrictions-on-advanced-ai-to-pass-ny-legislature"
    title: "New York Legislature Approves Sweeping AI Safety Measure (1)"
  - url: "https://www.technologyreview.com/2025/01/09/1109875/a-new-york-legislator-wants-to-pick-up-the-pieces-of-the-dead-california-ai-bill/"
    title: "A New York legislator wants to pick up the pieces of the dead California AI bill"
---

New York State has taken a significant step towards addressing the potential dangers of advanced artificial intelligence by passing a bill designed to prevent AI-fueled disasters. The legislation, which has cleared the state legislature and awaits the governor's signature, focuses on regulating powerful, cutting-edge AI models developed by companies like OpenAI, Google, and Anthropic.

The core intent of the bill is to hold developers of these 'frontier' AI models accountable for potential public safety threats. This includes scenarios ranging from enabling sophisticated cyberattacks to facilitating the development or deployment of bioweapons.

Key provisions of the proposed law require AI companies to implement robust safety plans for the development and deployment of their most powerful models. These plans would need to demonstrate cybersecurity protections to prevent unauthorized access and detail procedures for testing and mitigating risks, especially those associated with post-training modifications. The bill also includes protections for whistleblowers who report potential critical harms.

The legislation defines 'critical harm' in terms of significant real-world consequences, such as the use of an AI model resulting in mass casualties (100 or more deaths or serious injuries) or causing at least $1 billion in damages through an act that, if committed by a human, would be a crime requiring intent or negligence. The bill targets models based on their computational power, covering those requiring over 10^26 FLOPs in training and costing more than $100 million â€“ a threshold designed to capture models more advanced than current systems like GPT-4.

This move positions New York at the forefront of state-level AI regulation, building on ideas previously explored in other states, such as the failed SB 1047 in California. While drawing some inspiration, the New York bill reportedly differs by not creating a new government body or mandating a 'kill switch' capability for models. The focus remains specifically on catastrophic risks from the most powerful AI, sparking some debate among experts who argue that regulatory efforts should also prioritize addressing more immediate harms like bias, discrimination, and job displacement.

As the bill moves towards potential enactment, it signals a growing legislative focus on proactively addressing the high-stakes risks associated with rapidly advancing artificial intelligence, aiming to establish guardrails before potential disasters occur.
